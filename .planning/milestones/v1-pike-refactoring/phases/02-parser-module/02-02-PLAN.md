---
phase: 02-parser-module
plan: 02
type: execute
wave: 2
depends_on: [02-01]
files_modified:
  - pike-scripts/LSP.pmod/Parser.pike
  - pike-scripts/analyzer.pike
autonomous: true

must_haves:
  truths:
    - "Parser.pike has tokenize_request, compile_request, and batch_parse_request methods"
    - "tokenize_request uses Parser.Pike.tokenize() for tokenization"
    - "compile_request uses master()->set_inhibit_compile_errors() for error capture"
    - "batch_parse_request calls parse_request for each file"
    - "analyzer.pike delegates tokenize, compile, and batch_parse to Parser class"
    - "Parser methods throw exceptions on error; handler wrappers catch them"
    - "Parser has no cache interaction per CONTEXT.md design decision"
  artifacts:
    - path: pike-scripts/LSP.pmod/Parser.pike
      provides: tokenize_request, compile_request, batch_parse_request methods
      contains: "tokenize_request", "compile_request", "batch_parse_request"
    - path: pike-scripts/analyzer.pike
      provides: Handler wrappers using Parser class
      contains: "handle_tokenize", "handle_compile", "handle_batch_parse"
  key_links:
    - from: Parser.batch_parse_request
      to: Parser.parse_request
      via: method call
      pattern: "parse_request"
    - from: Parser.tokenize_request
      to: analyzer.handle_tokenize
      via: exception propagation
      pattern: "throws on error"
    - from: Parser.compile_request
      to: analyzer.handle_compile
      via: exception propagation
      pattern: "throws on error"
    - from: Parser.batch_parse_request
      to: analyzer.handle_batch_parse
      via: exception propagation
      pattern: "throws on error"
    - from: analyzer.handle_tokenize
      to: Parser.tokenize_request
      via: delegation with catch wrapper
      pattern: "catch.*parser->tokenize_request"
    - from: analyzer.handle_compile
      to: Parser.compile_request
      via: delegation with catch wrapper
      pattern: "catch.*parser->compile_request"
    - from: analyzer.handle_batch_parse
      to: Parser.batch_parse_request
      via: delegation with catch wrapper
      pattern: "catch.*parser->batch_parse_request"
---

<objective>
Add tokenize, compile, and batch_parse methods to Parser.pike and update analyzer.pike to delegate to these methods

Purpose: Complete the Parser class with all three remaining parsing handlers, following the same pattern as parse_request. Parser methods throw exceptions; handler wrappers catch them per CONTEXT.md design decision ("Parser accumulates errors in result structure; caller decides whether to log").

Note on cache: Per CONTEXT.md, "Parser has no cache. This is critical." Cache interaction remains in analyzer.pike handler layer (the caller), not in Parser.pike. This plan correctly implements stateless Parser design.

Output: Parser.pike with tokenize_request, compile_request, batch_parse_request methods; analyzer.pike updated to delegate
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-parser-module/02-CONTEXT.md
@.planning/phases/02-parser-module/02-RESEARCH.md
@.planning/phases/02-parser-module/02-01-SUMMARY.md
@pike-scripts/analyzer.pike
@pike-scripts/LSP.pmod/Parser.pike
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add tokenize_request method to Parser.pike</name>
  <files>pike-scripts/LSP.pmod/Parser.pike</files>
  <action>
Add tokenize_request method to Parser class, extracted from analyzer.pike handle_tokenize (lines 452-486):

```pike
//! Tokenize Pike source code
//! @param params Mapping with "code" key
//! @returns Mapping with "result" containing "tokens" array
//! @throws On tokenization errors (caller catches)
mapping tokenize_request(mapping params)
```

Implementation:
1. Extract code from params: `string code = params->code || "";`
2. Use Parser.Pike.split() and Parser.Pike.tokenize() to get tokens
3. Build result array with text, line, file for each token
4. Return `(["result": (["tokens": tokens])])`

Key points:
- No migration needed (no String.trim_whites in this function)
- DO NOT include catch block - let exceptions propagate to handler wrapper
- Use same result structure as original

The function should:
```pike
mapping tokenize_request(mapping params) {
    string code = params->code || "";
    array tokens = ({});

    array(string) split_tokens = Parser.Pike.split(code);
    array pike_tokens = Parser.Pike.tokenize(split_tokens);

    foreach (pike_tokens, mixed t) {
        tokens += ({
            ([
                "text": t->text,
                "line": t->line,
                "file": t->file
            ])
        });
    }

    return ([
        "result": ([
            "tokens": tokens
        ])
    ]);
}
```

Per CONTEXT.md: "Parser should NOT depend on LSP types... Parser accumulates errors in result structure; caller decides whether to log." The handler wrapper (Task 4) provides the catch block.
  </action>
  <verify>
    pike -Mpike-scripts -e "import LSP; Parser p = Parser(); mapping res = p->tokenize_request(([\"code\": \"int x = 5;\"])); werror('%d tokens\\n', sizeof(res->result->tokens));"
    Should output tokens count > 0.
  </verify>
  <done>
    tokenize_request method exists in Parser class
    Returns token stream from Pike source code
    Throws exceptions on error (handler catches)
  </done>
</task>

<task type="auto">
  <name>Task 2: Add compile_request method to Parser.pike</name>
  <files>pike-scripts/LSP.pmod/Parser.pike</files>
  <action>
Add compile_request method to Parser class, extracted from analyzer.pike handle_compile (lines 488-542):

```pike
//! Compile Pike source code and capture diagnostics
//! @param params Mapping with "code" and "filename" keys
//! @returns Mapping with "result" containing "symbols" and "diagnostics"
//! @throws On compilation errors (caller catches)
mapping compile_request(mapping params)
```

Implementation:
1. Extract code and filename from params
2. Set up capture_error and capture_warning functions
3. Use master()->set_inhibit_compile_errors() to capture compilation errors
4. Call compile_string() with error capture
5. Restore old error handler
6. Return `(["result": (["symbols": ({}), "diagnostics": diagnostics])])`

Key points:
- No migration needed (no String.trim_whites in this function)
- Keep the capture_error and capture_warning nested functions
- Keep master()->set_inhibit_compile_errors() pattern
- Return same result structure as original
- DO NOT include outer catch block - let exceptions propagate to handler wrapper

The function should follow this structure:
```pike
mapping compile_request(mapping params) {
    string code = params->code || "";
    string filename = params->filename || "input.pike";

    array diagnostics = ({});

    // Capture compilation errors using set_inhibit_compile_errors
    void capture_error(string file, int line, string msg) {
        diagnostics += ({
            ([
                "message": msg,
                "severity": "error",
                "position": ([
                    "file": file,
                    "line": line
                ])
            ])
        });
    };

    // Capture warnings too
    void capture_warning(string file, int line, string msg) {
        diagnostics += ({
            ([
                "message": msg,
                "severity": "warning",
                "position": ([
                    "file": file,
                    "line": line
                ])
            ])
        });
    };

    // Save old handlers
    mixed old_error = master()->get_inhibit_compile_errors();

    // Set our capture handlers
    master()->set_inhibit_compile_errors(capture_error);

    // Try to compile
    compile_string(code, filename);

    // Restore old handler
    master()->set_inhibit_compile_errors(old_error);

    return ([
        "result": ([
            "symbols": ({}),
            "diagnostics": diagnostics
        ])
    ]);
}
```

Per CONTEXT.md: "Parser should NOT depend on LSP types... Parser accumulates errors in result structure; caller decides whether to log." The handler wrapper (Task 4) provides the catch block.
  </action>
  <verify>
    pike -Mpike-scripts -e "import LSP; Parser p = Parser(); mapping res = p->compile_request(([\"code\": \"int x = ;\", \"filename\": \"test.pike\"])); werror('%d diagnostics\\n', sizeof(res->result->diagnostics));"
    Should output diagnostics count > 0 for syntax error.
  </verify>
  <done>
    compile_request method exists in Parser class
    Captures compilation diagnostics using master()->set_inhibit_compile_errors()
    Returns diagnostics array with error/warning information
    Throws exceptions on error (handler catches)
  </done>
</task>

<task type="auto">
  <name>Task 3: Add batch_parse_request method to Parser.pike</name>
  <files>pike-scripts/LSP.pmod/Parser.pike</files>
  <action>
Add batch_parse_request method to Parser class, extracted from analyzer.pike handle_batch_parse (lines 2007-2064):

```pike
//! Parse multiple Pike source files in a single request
//! @param params Mapping with "files" array (each with "code" and "filename")
//! @returns Mapping with "result" containing "results" array and "count"
//! @throws On batch processing errors (caller catches)
mapping batch_parse_request(mapping params)
```

Implementation:
1. Extract files array from params
2. For each file:
   - Call parse_request() (internal method call, not via instance)
   - On error: catch per-file exception, return result with error diagnostic
   - On success: extract symbols and diagnostics
3. Return `(["result": (["results": results, "count": sizeof(results)])])`

Key points:
- Call parse_request directly (this->parse_request()) not via new Parser instance
- Keep per-file error catching (continues even if one file fails)
- DO NOT include outer catch block around the entire batch - let unexpected exceptions propagate to handler wrapper
- No migration needed (no String.trim_whites in this function)

The function should:
```pike
mapping batch_parse_request(mapping params) {
    array files = params->files || ({});
    array results = ({});

    foreach (files, mapping file_info) {
        string code = file_info->code || "";
        string filename = file_info->filename || "unknown.pike";

        // Try to parse each file, continuing even if one fails
        mixed parse_err;
        mapping parse_result;

        parse_err = catch {
            parse_result = parse_request(([
                "code": code,
                "filename": filename,
                "line": 1
            ]));
        };

        if (parse_err) {
            // On error, return result with error diagnostic
            results += ({
                ([
                    "filename": filename,
                    "symbols": ({}),
                    "diagnostics": ({
                        ([
                            "severity": "error",
                            "message": "Parse error: " + describe_error(parse_err),
                            "position": ([
                                "file": filename,
                                "line": 1
                            ])
                        ])
                    })
                ])
            });
        } else {
            // Extract results from parse response
            mapping parse_data = parse_result->result || ([]);
            results += ({
                ([
                    "filename": filename,
                    "symbols": parse_data->symbols || ({}),
                    "diagnostics": parse_data->diagnostics || ({})
                ])
            });
        }
    }

    return ([
        "result": ([
            "results": results,
            "count": sizeof(results)
        ])
    ]);
}
```

Note: Per-file catch blocks are appropriate here (error recovery pattern - continue processing other files). The outer function does NOT have a catch block - unexpected errors propagate to handler wrapper.

Per CONTEXT.md: "Parser accumulates errors in result structure; caller decides whether to log."
  </action>
  <verify>
    pike -Mpike-scripts -e "import LSP; Parser p = Parser(); mapping res = p->batch_parse_request(([\"files\": ({([\"code\": \"int x;\", \"filename\": \"1.pike\"]), ([\"code\": \"string y;\", \"filename\": \"2.pike\"])})])); werror('%d files processed\\n', res->result->count);"
    Should output 2 files processed.
  </verify>
  <done>
    batch_parse_request method exists in Parser class
    Calls parse_request for each file
    Returns results array with symbols and diagnostics per file
    Continues processing even if individual file fails (per-file catch)
    Throws exceptions on unexpected errors (handler catches)
  </done>
</task>

<task type="auto">
  <name>Task 4: Update analyzer.pike to delegate tokenize, compile, and batch_parse to Parser</name>
  <files>pike-scripts/analyzer.pike</files>
  <action>
Modify analyzer.pike to replace handle_tokenize, handle_compile, and handle_batch_parse with thin wrappers:

Per CONTEXT.md: "Parser should NOT depend on LSP types... Parser accumulates errors in result structure; caller decides whether to log." These handler wrappers provide the catch blocks that convert Parser exceptions into JSON-RPC error responses.

Also per CONTEXT.md on cache: "Parser has no cache. This is critical." Cache interaction (if any) remains in analyzer.pike handler layer, not in Parser.pike.

1. Replace handle_tokenize (lines 452-486):
```pike
protected mapping handle_tokenize(mapping params) {
  Parser parser = Parser();

  mixed err = catch {
    return parser->tokenize_request(params);
  };

  return ([
    "error": ([
      "code": -32000,
      "message": describe_error(err)
    ])
  ]);
}
```

2. Replace handle_compile (lines 488-542):
```pike
protected mapping handle_compile(mapping params) {
  Parser parser = Parser();

  mixed err = catch {
    return parser->compile_request(params);
  };

  return ([
    "error": ([
      "code": -32000,
      "message": describe_error(err)
    ])
  ]);
}
```

3. Replace handle_batch_parse (lines 2007-2064):
```pike
protected mapping handle_batch_parse(mapping params) {
  Parser parser = Parser();

  mixed err = catch {
    return parser->batch_parse_request(params);
  };

  return ([
    "error": ([
      "code": -32000,
      "message": describe_error(err)
    ])
  ]);
}
```

Note: The old implementations are now in Parser.pike, so replace entire functions.
Note: These handler wrappers provide the error catching that converts Parser exceptions to JSON-RPC errors.
  </action>
  <verify>
    pike pike-scripts/analyzer.pike
    Test tokenize: {"jsonrpc":"2.0","method":"tokenize","params":{"code":"int x=5;"},"id":1}
    Test compile: {"jsonrpc":"2.0","method":"compile","params":{"code":"int x=;","filename":"test.pike"},"id":1}
    Test batch_parse: {"jsonrpc":"2.0","method":"batch_parse","params":{"files":[{"code":"int x;","filename":"1.pike"}]},"id":1}
    All should return valid JSON responses.
  </verify>
  <done>
    handle_tokenize delegates to Parser.tokenize_request with catch wrapper
    handle_compile delegates to Parser.compile_request with catch wrapper
    handle_batch_parse delegates to Parser.batch_parse_request with catch wrapper
    All handlers wrap exceptions in JSON-RPC error responses
    Old implementations removed from analyzer.pike
    Parser remains stateless with no cache interaction
  </done>
</task>

</tasks>

<verification>
1. Parser.pike has tokenize_request, compile_request, and batch_parse_request methods
2. tokenize_request uses Parser.Pike.split() and Parser.Pike.tokenize()
3. compile_request uses master()->set_inhibit_compile_errors() for error capture
4. batch_parse_request calls parse_request for each file
5. Parser methods do NOT have outer catch blocks - they throw on error
6. analyzer.pike handle_tokenize, handle_compile, handle_batch_parse delegate to Parser
7. Handler wrappers have catch blocks returning JSON-RPC errors
8. Parser has no cache interaction (stateless per CONTEXT.md)
9. End-to-end: JSON-RPC requests for tokenize, compile, batch_parse work correctly
</verification>

<success_criteria>
1. Parser class has all four public methods: parse_request, tokenize_request, compile_request, batch_parse_request
2. Parser methods throw exceptions on error (no outer catch blocks)
3. analyzer.pike delegates all four handlers to Parser class
4. Handler wrappers provide catch blocks converting exceptions to JSON-RPC errors
5. JSON-RPC protocol unchanged - client sees same response format
6. No string trimming, cache access, or constant duplication in Parser.pike
7. Error handling flow: Parser throws → handler catches → returns JSON-RPC error
</success_criteria>

<output>
After completion, create `.planning/phases/02-parser-module/02-02-SUMMARY.md`
</output>
