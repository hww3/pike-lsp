---
phase: 04-analysis-and-entry-point
plan: 06
type: execute
wave: 3
depends_on: [04-05]
files_modified:
  - test/tests/analysis-tests.pike
  - test/tests/response-format-tests.pike
autonomous: true

must_haves:
  truths:
    - "Analysis.pike has integration tests for all three handlers"
    - "find_occurrences tests verify identifier extraction and keyword filtering"
    - "analyze_uninitialized tests detect uninitialized variable usage"
    - "get_completion_context tests verify context detection (member, scope, identifier)"
    - "Full JSON-RPC cycle test verifies request/response through router"
    - "Response format tests verify backward compatibility"
  artifacts:
    - path: "test/tests/analysis-tests.pike"
      provides: "Integration tests for Analysis.pike handlers"
      min_lines: 200
    - path: "test/tests/response-format-tests.pike"
      provides: "Schema-style tests for JSON-RPC response format verification"
      min_lines: 150
  key_links:
    - from: "analysis-tests.pike"
      to: "LSP.Analysis"
      via: "master()->resolv() pattern for test isolation"
      pattern: "master()->resolv\\(\"LSP.Analysis\"\\)"
    - from: "response-format-tests.pike"
      to: "pike-scripts/analyzer.pike"
      via: "full JSON-RPC request/response cycle"
      pattern: "handle_request|dispatch"
---

## ⚠️ CRITICAL: READ FIRST ⚠️

All code changes require extension tests using MockOutputChannel pattern.
See "MANDATORY: Extension Testing Setup" section below.
No exceptions. No "later". Tests first.

---

## MANDATORY: Extension Testing Setup

### STOP — Read This Before Any Implementation

This testing infrastructure MUST be implemented and used before ANY refactoring work is considered complete. This is not optional.

### Required Stack

- `@vscode/test-electron`
- `mocha`
- `@types/mocha`
- `glob`

### Required Pattern

#### 1. Mock Output Channel (Create First)

```typescript
// src/test/mockOutputChannel.ts
export class MockOutputChannel implements vscode.OutputChannel {
    public logs: string[] = [];

    append(value: string): void {
        this.logs.push(value);
        console.log(value);
    }

    appendLine(value: string): void {
        this.logs.push(value + '\n');
        console.log(value);
    }

    // ... implement other required methods
    show(): void {}
    hide(): void {}
    dispose(): void {}
    clear(): void {}
    get name(): string { return 'MockOutput'; }
}
```

#### 2. Extension API Export (Modify activate)

```typescript
// src/extension.ts
export interface ExtensionAPI {
    client: LanguageClient;
    outputChannel: MockOutputChannel;
}

export async function activate(context: vscode.ExtensionContext): Promise<ExtensionAPI> {
    const outputChannel = new MockOutputChannel();
    const client = new LanguageClient(..., outputChannel);

    // ... rest of activation

    return { client, outputChannel };
}
```

#### 3. Test Structure

```typescript
// src/test/extension.test.ts
import * as vscode from 'vscode';
import { ExtensionAPI } from '../extension';

suite('Extension Test Suite', () => {
    let api: ExtensionAPI;

    suiteSetup(async () => {
        const ext = vscode.extensions.getExtension('pike-lsp.vscode-pike');
        api = await ext.activate();
    });

    test('LSP initializes without errors', () => {
        const errors = api.outputChannel.logs.filter(l => l.includes('Error'));
        assert.strictEqual(errors.length, 0, `Errors found: ${errors.join('\n')}`);
    });

    test('Stdio module loads without timeout', () => {
        const timeouts = api.outputChannel.logs.filter(l => l.includes('timed out'));
        assert.strictEqual(timeouts.length, 0);
    });
});
```

### Verification Checklist

- [ ] MockOutputChannel class exists and implemented
- [ ] Extension activate() returns ExtensionAPI
- [ ] Test file exists at src/test/extension.test.ts
- [ ] `npm test` runs extension tests
- [ ] Tests verify no errors in output channel
- [ ] Tests verify no timeouts in output channel
- [ ] Tests verify stdlib introspection works

### Agent Instructions

```
BLOCKING REQUIREMENT:

1. Implement MockOutputChannel FIRST
2. Modify activate() to return API SECOND
3. Create test file THIRD
4. Run tests FOURTH
5. Only proceed with other work if tests pass

If you skip these steps, your work is REJECTED.

Do not:
- Say "I'll add tests later"
- Skip to implementation without tests
- Assume code works without running tests
- Mark phase complete without test output showing PASS
```

---

<objective>
Create comprehensive integration tests for Analysis.pike handlers and full JSON-RPC cycle verification. This plan ensures all three Analysis handlers work correctly and the router properly delegates requests while maintaining backward-compatible response formats.

Purpose: Validate the complete modularization by testing:
1. Each Analysis handler independently (find_occurrences, analyze_uninitialized, get_completion_context)
2. Full JSON-RPC request/response cycle through the router
3. Backward compatibility of response formats (per CONTEXT.md compatible enhancement rule)

Output: test/tests/analysis-tests.pike with handler integration tests and test/tests/response-format-tests.pike with JSON-RPC format verification tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-analysis-and-entry-point/04-CONTEXT.md
@.planning/phases/04-analysis-and-entry-point/04-RESEARCH.md
@.planning/phases/04-analysis-and-entry-point/04-05-SUMMARY.md
@.planning/phases/03-intelligence-module**---extract-introspection-and-resolution-handlers/03-04-SUMMARY.md
@.planning/phases/02-parser-module/02-03-SUMMARY.md
@test/tests/intelligence-tests.pike
@test/tests/parser-tests.pike
@pike-scripts/analyzer.pike
@pike-scripts/LSP.pmod/Analysis.pike
</context>

<tasks>

<task type="auto">
  <name>Create analysis-tests.pike with handler integration tests</name>
  <files>test/tests/analysis-tests.pike</files>
  <action>
    Create test/tests/analysis-tests.pike following the pattern from intelligence-tests.pike.

    File structure:
    ```pike
    #!/usr/bin/env pike
    //! LSP Analysis Tests
    //!
    //! Integration tests for LSP.Analysis class:
    //! - handle_find_occurrences: Extract identifiers using tokenization
    //! - handle_analyze_uninitialized: Detect uninitialized variable usage
    //! - handle_get_completion_context: Determine completion context at position
    //!
    //! Run with: pike test/tests/analysis-tests.pike

    int test_count = 0;
    int pass_count = 0;
    int fail_count = 0;
    array(string) failure_messages = ({});

    //! Setup module path
    void setup_module_path() {
        string script_path = __FILE__;
        string base_path = dirname(script_path);
        for (int i = 0; i < 10; i++) {
            if (basename(base_path) == "pike-lsp") break;
            string parent = dirname(base_path);
            if (parent == base_path) break;
            base_path = parent;
        }
        string pike_scripts_path = combine_path(base_path, "pike-scripts");
        master()->add_module_path(pike_scripts_path);
    }

    //! Get Analysis class
    mixed get_analysis() {
        return master()->resolv("LSP.Analysis")->Analysis;
    }

    //! Run a single test
    void run_test(function test_func, string name) {
        test_count++;
        mixed err = catch {
            test_func();
            pass_count++;
            write("\\033[32m[PASS]\\033[0m %s\\n", name);
        };
        if (err) {
            fail_count++;
            failure_messages += ({ name });
            write("\\033[31m[FAIL]\\033[0m %s\\n", name);
            if (arrayp(err)) {
                write("    Error: %s\\n", err[0] || "Unknown error");
            } else {
                write("    Error: %s\\n", sprintf("%O", err));
            }
        }
    }
    ```

    Test functions to add:

    **find_occurrences tests:**
    - test_find_occurrences_basic: Extracts identifiers from simple code
    - test_find_occurrences_filters_keywords: Excludes if/for/while etc.
    - test_find_occurrences_includes_positions: Each has text, line, character
    - test_find_occurrences_empty_code: Returns empty occurrences array
    - test_find_occurrences_tokenization_error: Returns error response

    **analyze_uninitialized tests:**
    - test_uninitialized_string_warns: Detects uninitialized string usage
    - test_uninitialized_int_no_warn: int auto-initializes, no warning
    - test_uninitialized_after_declaration: No warning if initialized
    - test_uninitialized_branch_tracking: Warns for maybe-init branches
    - test_uninitialized_function_params: Parameters are pre-initialized
    - test_uninitialized_tokenization_error: Returns empty diagnostics

    **get_completion_context tests:**
    - test_completion_member_access_arrow: Detects foo->bar context
    - test_completion_member_access_dot: Detects foo.bar context
    - test_completion_scope_access: Detects module::symbol context
    - test_completion_identifier: Plain identifier context
    - test_completion_position_accuracy: Correct token at cursor position
    - test_completion_tokenization_error: Returns "none" context

    Main test runner:
    ```pike
    int main(int argc, array(string) argv) {
        setup_module_path();

        write("LSP Analysis Tests\\n");
        write("===================\\n\\n");

        // find_occurrences tests
        run_test(test_find_occurrences_basic, "find_occurrences: extracts identifiers");
        run_test(test_find_occurrences_filters_keywords, "find_occurrences: filters keywords");
        // ... etc

        // analyze_uninitialized tests
        run_test(test_uninitialized_string_warns, "uninitialized: string usage warns");
        // ... etc

        // get_completion_context tests
        run_test(test_completion_member_access_arrow, "completion: detects -> access");
        // ... etc

        write("\\n");
        write("===================\\n");
        write("Tests: %d, Passed: %d, Failed: %d\\n", test_count, pass_count, fail_count);

        return fail_count > 0 ? 1 : 0;
    }
    ```

    Expected: 15-18 tests total covering all three handlers.
  </action>
  <verify>pike test/tests/analysis-tests.pike</verify>
  <done>All analysis tests pass (15+ tests covering find_occurrences, analyze_uninitialized, get_completion_context)</done>
</task>

<task type="auto">
  <name>Create response-format-tests.pike with backward compatibility tests</name>
  <files>test/tests/response-format-tests.pike</files>
  <action>
    Create test/tests/response-format-tests.pike to verify JSON-RPC response format compatibility per CONTEXT.md.

    Purpose: Ensure the router doesn't break existing VSCode extension by:
    - Preserving required response fields
    - Maintaining correct field types
    - Keeping response structure unchanged

    File structure:
    ```pike
    #!/usr/bin/env pike
    //! LSP Response Format Tests
    //!
    //! Schema-style tests for JSON-RPC response format verification.
    //! Ensures backward compatibility after modularization.
    //!
    //! Run with: pike test/tests/response-format-tests.pike

    // Test infrastructure (same pattern as analysis-tests.pike)
    int test_count = 0;
    int pass_count = 0;
    int fail_count = 0;
    // ... setup_module_path, run_test, etc.

    // Load analyzer for full cycle testing
    program AnalyzerProg = master()->resolv("main.analyzer");

    //! Helper: Verify response has required field
    int has_field(mapping response, string field_path) {
        array parts = field_path / ".";
        mixed current = response;
        foreach (parts, string part) {
            if (!mappingp(current) || !current[part]) return 0;
            current = current[part];
        }
        return 1;
    }

    //! Helper: Verify field type
    int field_type_is(mapping response, string field_path, string expected_type) {
        array parts = field_path / ".";
        mixed current = response;
        foreach (parts, string part) {
            if (!mappingp(current) || !current[part]) return 0;
            current = current[part];
        }
        if (expected_type == "array") return arrayp(current);
        if (expected_type == "mapping") return mappingp(current);
        if (expected_type == "string") return stringp(current);
        if (expected_type == "int") return intp(current);
        return 0;
    }
    ```

    Test functions (one per handler):

    - test_parse_response_format: Parse handler returns result.symbols (array)
    - test_introspect_response_format: Introspect returns result.symbols, result.success
    - test_resolve_response_format: Resolve returns result.exists (int), result.path
    - test_find_occurrences_response_format: Occurrences returns result.occurrences (array)
    - test_analyze_uninitialized_response_format: Uninitialized returns result.diagnostics (array)
    - test_completion_context_response_format: Completion returns result.context, result.prefix
    - test_error_response_format: Errors have error.code (int), error.message (string)
    - test_jsonrpc_envelope: Responses have jsonrpc: "2.0" and id from request

    Example test:
    ```pike
    void test_find_occurrences_response_format() {
        mapping request = ([
            "jsonrpc": "2.0",
            "id": 1,
            "method": "find_occurrences",
            "params": (["code": "int x; string y;"])
        ]);

        // Simulate routing through dispatch
        Context ctx = Context();
        mapping response = dispatch("find_occurrences", request->params, ctx);

        // Verify structure
        assert(has_field(response, "result.occurrences"),
               "find_occurrences response has result.occurrences");
        assert(field_type_is(response, "result.occurrences", "array"),
               "result.occurrences is an array");

        // Verify occurrence structure if array not empty
        if (sizeof(response->result->occurrences) > 0) {
            mapping occ = response->result->occurrences[0];
            assert(occ->text && occ->line && occ->character,
                   "occurrence has text, line, character fields");
        }
    }

    void assert(int condition, string message) {
        if (!condition) {
            throw({"Assertion failed: " + message});
        }
    }
    ```

    Expected: 8-10 tests verifying all 12 handlers have correct response format.
  </action>
  <verify>pike test/tests/response-format-tests.pike</verify>
  <done>All response format tests pass (verifying all 12 handlers maintain compatible structure)</done>
</task>

<task type="auto">
  <name>Create test fixtures for Analysis tests</name>
  <files>test/fixtures/analysis/</files>
  <action>
    Create test/fixtures/analysis/ directory with fixture files for integration testing.

    Fixtures to create:

    test/fixtures/analysis/uninitialized.pike:
    ```pike
    //! Test fixture for uninitialized variable analysis

    // This should warn: s used before initialization
    void test_uninitialized_string() {
        string s;
        write("%s\n", s);  // Warning: s may be uninitialized
    }

    // This should NOT warn: int auto-initializes
    void test_initialized_int() {
        int i;
        write("%d\n", i);  // OK: int defaults to 0
    }

    // This should NOT warn: initialized before use
    void test_initialized_string() {
        string s = "hello";
        write("%s\n", s);  // OK: s is initialized
    }

    // Branch analysis test
    void test_branch_init() {
        string s;
        if (random(2) > 0) {
            s = "initialized";
        }
        write("%s\n", s);  // Warning: s may be uninitialized
    }
    ```

    test/fixtures/analysis/completion.pike:
    ```pike
    //! Test fixture for completion context

    class MyClass {
        int value;

        void method() {
            // Member access: this->value
            // Should detect: context=member_access, operator=->, objectName=this
        }
    }

    module->function();  // Scope access

    void test_plain() {
        int identifie  // Cursor here -> plain identifier completion
    }
    ```

    test/fixtures/analysis/occurrences.pike:
    ```pike
    //! Test fixture for find_occurrences

    int myVariable = 5;
    string myVariable2 = "test";

    void function() {
        int x = myVariable + myVariable2;
        // Should find: myVariable, myVariable2, x, function
        // Should NOT find: int, string, void
    }
    ```

    Fixtures allow testing with realistic Pike code patterns.
  </action>
  <verify>ls -la test/fixtures/analysis/</verify>
  <done>Three fixture files exist: uninitialized.pike, completion.pike, occurrences.pike</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. Run pike test/tests/analysis-tests.pike - all tests pass
2. Run pike test/tests/response-format-tests.pike - all tests pass
3. Verify test count (15+ analysis tests, 8+ format tests)
4. Verify fixtures exist in test/fixtures/analysis/
5. Test JSON-RPC round trip manually (echo request | pike analyzer.pike)
</verification>

<success_criteria>
1. analysis-tests.pike exists with 15+ tests
2. All find_occurrences tests pass
3. All analyze_uninitialized tests pass
4. All get_completion_context tests pass
5. response-format-tests.pike exists with 8+ tests
6. All response format tests pass
7. Test fixtures directory created with 3 fixture files
8. Full JSON-RPC cycle verified working
9. No breaking changes to response structure
10. Tests can run independently
</success_criteria>

<output>
After completion, create `.planning/phases/04-analysis-and-entry-point/04-06-SUMMARY.md`
</output>
