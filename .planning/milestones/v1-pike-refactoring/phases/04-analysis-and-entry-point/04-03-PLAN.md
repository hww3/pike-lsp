---
phase: 04-analysis-and-entry-point
plan: 03
type: execute
wave: 2
depends_on: [04-01]
files_modified:
  - pike-scripts/LSP.pmod/Analysis.pike
autonomous: true

must_haves:
  truths:
    - "handle_analyze_uninitialized detects variables used before initialization"
    - "Only warns for types that need initialization (string, array, mapping, object, etc.)"
    - "Int/float don't warn (auto-initialize to 0)"
    - "Analyzes function/method bodies with scope tracking"
    - "Handles if/else branches with variable state tracking"
    - "Tokenization errors return empty diagnostics (not crash)"
  artifacts:
    - path: "pike-scripts/LSP.pmod/Analysis.pike"
      provides: "Stateless analysis class with handle_analyze_uninitialized and scope analysis"
      contains: "handle_analyze_uninitialized"
      exports: ["handle_analyze_uninitialized"]
  key_links:
    - from: "handle_analyze_uninitialized"
      to: "Parser.Pike"
      via: "Parser.Pike.split() and Parser.Pike.tokenize() for code tokenization"
      pattern: "Parser\\.Pike\\.(split|tokenize)"
    - from: "analyze_uninitialized_impl"
      to: "analyze_scope"
      via: "protected helper for top-level scope analysis"
      pattern: "analyze_scope"
    - from: "analyze_scope"
      to: "analyze_function_body"
      via: "protected helper for function-level analysis"
      pattern: "analyze_function_body"
---

<objective>
Add handle_analyze_uninitialized method and all scope analysis helpers to Analysis.pike class. This is the most complex analysis handler, implementing variable initialization tracking across scopes, branches, and function bodies.

Purpose: Extract the uninitialized variable analysis handler (analyzer.pike lines 1545-2299) into the modular Analysis class. This handler performs sophisticated dataflow analysis to detect variables that are read before being written, with awareness of control flow.

Output: Analysis.pike with handle_analyze_uninitialized method and protected helpers for scope analysis, function body analysis, and variable tracking.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-analysis-and-entry-point/04-CONTEXT.md
@.planning/phases/04-analysis-and-entry-point/04-RESEARCH.md
@.planning/phases/04-analysis-and-entry-point/04-01-SUMMARY.md
@pike-scripts/analyzer.pike
@pike-scripts/LSP.pmod/Analysis.pike
</context>

<tasks>

<task type="auto">
  <name>Add class constants for uninitialized analysis to Analysis.pike</name>
  <files>pike-scripts/LSP.pmod/Analysis.pike</files>
  <action>
    Add class constants at the top of Analysis class (after create() method) extracted from analyzer.pike lines 1531-1540.

    State constants:
    ```pike
    constant STATE_UNINITIALIZED = 0;  // Never assigned
    constant STATE_MAYBE_INIT = 1;     // Assigned in some branches only
    constant STATE_INITIALIZED = 2;    // Definitely assigned
    constant STATE_UNKNOWN = 3;        // Can't determine
    ```

    Types that need initialization multiset:
    ```pike
    constant NEEDS_INIT_TYPES = (<
        "string", "array", "mapping", "multiset",
        "object", "function", "program", "mixed"
    >);
    ```

    These constants control the analysis behavior. Only types in NEEDS_INIT_TYPES generate warnings because int/float auto-initialize to 0 in Pike.
  </action>
  <verify>grep -n "constant STATE_" pike-scripts/LSP.pmod/Analysis.pike | head -5</verify>
  <done>All four STATE constants and NEEDS_INIT_TYPES multiset exist in Analysis class</done>
</task>

<task type="auto">
  <name>Add handle_analyze_uninitialized entry point to Analysis.pike</name>
  <files>pike-scripts/LSP.pmod/Analysis.pike</files>
  <action>
    Add handle_analyze_uninitialized method to Analysis class (extracted from analyzer.pike lines 1545-1566).

    Method signature:
    ```pike
    mapping handle_analyze_uninitialized(mapping params)
    ```

    Implementation:
    1. Extract params: code (default ""), filename (default "input.pike")
    2. Initialize empty diagnostics array
    3. Wrap analyze_uninitialized_impl call in catch
    4. On error: debug log and return empty diagnostics (not crash)
    5. Return result mapping with diagnostics array

    IMPORTANT: Unlike other handlers, this returns empty diagnostics on error rather than an error response. This is intentional - partial analysis is better than no analysis.

    Response structure:
    ```pike
    return ([
        "result": ([
            "diagnostics": diagnostics
        ])
    ]);
    ```
  </action>
  <verify>grep -n "handle_analyze_uninitialized" pike-scripts/LSP.pmod/Analysis.pike</verify>
  <done>handle_analyze_uninitialized method exists with error handling</done>
</task>

<task type="auto">
  <name>Add analyze_uninitialized_impl and analyze_scope protected helpers</name>
  <files>pike-scripts/LSP.pmod/Analysis.pike</files>
  <action>
    Add analyze_uninitialized_impl and analyze_scope protected methods (extracted from analyzer.pike lines 1569-1709).

    analyze_uninitialized_impl(string code, string filename):
    - Tokenize code using Parser.Pike.split/tokenize
    - Split code into lines for position lookup
    - Call analyze_scope with token range
    - Return diagnostics array (empty on tokenization error)

    analyze_scope(array tokens, array lines, string filename, int start_idx, int end_idx):
    - Initialize variables mapping for tracking
    - Track scope_depth and in_function_body
    - Iterate tokens, handle:
      - { } : scope depth changes, remove out-of-scope vars
      - lambda/function definitions: recurse via analyze_function_body
      - class definitions: recurse via analyze_scope
    - Return accumulated diagnostics array

    IMPORTANT MIGRATION:
    - Replace String.trim_whites() with LSP.Compat.trim_whites()
    - Tokenization errors return empty array gracefully

    Key patterns:
    - Call is_lambda_definition() to detect lambdas
    - Call is_function_definition() to detect functions
    - Call extract_function_params() to get parameters as pre-initialized vars
    - Call analyze_function_body() for function/lambda bodies
    - Call find_next_token() to find braces and parens
  </action>
  <verify>grep -n "protected.*analyze_uninitialized_impl\|protected.*analyze_scope" pike-scripts/LSP.pmod/Analysis.pike</verify>
  <done>analyze_uninitialized_impl and analyze_scope methods exist as protected helpers</done>
</task>

<task type="auto">
  <name>Add analyze_function_body and variable tracking helpers to Analysis.pike</name>
  <files>pike-scripts/LSP.pmod/Analysis.pike</files>
  <action>
    Add analyze_function_body and all variable tracking helpers (extracted from analyzer.pike lines 1712-2299).

    analyze_function_body(tokens, lines, filename, start_idx, end_idx, initial_vars):
    - Copy initial_vars (function parameters)
    - Track scope_depth and branch_stack
    - Handle block boundaries, lambdas
    - Detect variable declarations via is_type_keyword() and try_parse_declaration()
    - Track variable state (UNINITIALIZED, INITIALIZED, MAYBE_INIT, UNKNOWN)
    - Generate diagnostics for uninitialized reads
    - Handle if/else with branch state tracking
    - Handle foreach with loop variable initialization
    - Return diagnostics array

    Helper functions to add:
    - is_type_keyword(string text) - check if token is a Pike type keyword
    - is_identifier(string text) - check if token is an identifier
    - is_assignment_operator(string text) - check if token is =, +=, -=, etc.
    - try_parse_declaration(tokens, start_idx, end_idx) - parse variable declaration
    - is_function_definition(tokens, start_idx, end_idx) - detect function definition pattern
    - is_lambda_definition(tokens, start_idx, end_idx) - detect lambda definition pattern
    - extract_function_params(tokens, start_idx, body_start) - extract function parameters
    - find_next_token(tokens, start_idx, end_idx, target) - find token by text
    - find_next_meaningful_token(tokens, start_idx, end_idx) - skip whitespace/comments
    - find_prev_meaningful_token(tokens, start_idx, min_idx) - backwards skip whitespace
    - find_matching_brace(tokens, start_idx, end_idx) - find closing }
    - find_matching_paren(tokens, start_idx, end_idx) - find closing )
    - get_char_pos_in_line(lines, line_no, token_text) - position lookup
    - remove_out_of_scope_vars(variables, scope_depth) - cleanup
    - save_variable_states(variables) - snapshot for branch tracking
    - restore_variable_states(variables, saved) - restore after branch

    IMPORTANT MIGRATIONS:
    - Replace all String.trim_whites() with LSP.Compat.trim_whites()
    - All helpers marked as protected (not public API)

    Note: These are ~20 helper functions. Group them logically in the file:
    1. State/Type checking helpers (is_type_keyword, is_identifier, is_assignment_operator)
    2. Declaration parsing (try_parse_declaration)
    3. Definition detection (is_function_definition, is_lambda_definition)
    4. Parameter extraction (extract_function_params)
    5. Token navigation (find_next_token, find_matching_brace, etc.)
    6. Position lookup (get_char_pos_in_line)
    7. Variable management (remove_out_of_scope_vars, save/restore_variable_states)
  </action>
  <verify>for f in is_type_keyword is_identifier is_assignment_operator try_parse_declaration is_function_definition is_lambda_definition extract_function_params find_next_token find_next_meaningful_token find_prev_meaningful_token find_matching_brace find_matching_paren get_char_pos_in_line remove_out_of_scope_vars save_variable_states restore_variable_states; do grep -q "protected.*$f" pike-scripts/LSP.pmod/Analysis.pike || echo "Missing: $f"; done</verify>
  <done>All protected helper functions exist (verified: is_type_keyword, is_identifier, is_assignment_operator, try_parse_declaration, is_function_definition, is_lambda_definition, extract_function_params, find_next_token, find_next_meaningful_token, find_prev_meaningful_token, find_matching_brace, find_matching_paren, get_char_pos_in_line, remove_out_of_scope_vars, save_variable_states, restore_variable_states)</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. Load Analysis.pike and instantiate Analysis class
2. Call handle_analyze_uninitialized with code containing uninitialized string usage
3. Verify diagnostic returned with "Variable 'X' is used before being initialized"
4. Test with initialized variable - verify no diagnostic
5. Test with int/float - verify no diagnostic (auto-initialize to 0)
6. Test with if/else branches - verify branch-aware analysis
7. Verify tokenization errors return empty diagnostics array
</verification>

<success_criteria>
1. handle_analyze_uninitialized returns diagnostics array
2. Detects uninitialized string/array/mapping/object usage
3. Does NOT warn for int/float (auto-initialize)
4. Analyzes function bodies with parameter tracking
5. Handles if/else branches with state tracking
6. Handles foreach with loop variable initialization
7. Uses LSP.Compat.trim_whites() throughout
8. Tokenization errors gracefully return empty diagnostics
9. All ~20 helper functions are protected methods
</success_criteria>

<output>
After completion, create `.planning/phases/04-analysis-and-entry-point/04-03-SUMMARY.md`
</output>
