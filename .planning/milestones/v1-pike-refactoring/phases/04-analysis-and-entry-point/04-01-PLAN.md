---
phase: 04-analysis-and-entry-point
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pike-scripts/LSP.pmod/Analysis.pike
autonomous: true

must_haves:
  truths:
    - "Analysis.pike class exists and is loadable via import LSP.Analysis"
    - "handle_find_occurrences extracts all identifiers from Pike code using Parser.Pike tokenization"
    - "Filtering excludes Pike keywords (if, else, for, while, etc.)"
    - "Each occurrence has text, line, and character position"
    - "Tokenization errors return JSON-RPC error response"
  artifacts:
    - path: "pike-scripts/LSP.pmod/Analysis.pike"
      provides: "Stateless analysis class with handle_find_occurrences method"
      min_lines: 80
      exports: ["Analysis", "handle_find_occurrences"]
  key_links:
    - from: "Analysis.pike"
      to: "Parser.Pike"
      via: "Parser.Pike.split() and Parser.Pike.tokenize() calls"
      pattern: "Parser\\.Pike\\.(split|tokenize)"
    - from: "Analysis.pike"
      to: "LSP.Compat"
      via: "String.trim_whites() replacement for cross-version compatibility"
      pattern: "LSP\\.Compat\\.trim_whites"
---

<objective>
Extract handle_find_occurrences handler into Analysis.pike class as the first analysis handler. This handler uses Parser.Pike tokenization to find all identifier occurrences in Pike source code, filtering out keywords and operators.

Purpose: Establish Analysis.pike class following the stateless pattern from Parser.pike and Intelligence.pike. handle_find_occurrences is the simplest analysis handler (single pass tokenization, no complex state tracking), making it ideal for establishing the class structure.

Output: Loadable pike-scripts/LSP.pmod/Analysis.pike with stateless Analysis class containing handle_find_occurrences method and get_char_position helper.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-analysis-and-entry-point/04-CONTEXT.md
@.planning/phases/04-analysis-and-entry-point/04-RESEARCH.md
@.planning/phases/02-parser-module/02-01-SUMMARY.md
@.planning/phases/03-intelligence-module**---extract-introspection-and-resolution-handlers/03-01-SUMMARY.md
@pike-scripts/analyzer.pike
@pike-scripts/LSP.pmod/Parser.pike
@pike-scripts/LSP.pmod/Intelligence.pike
</context>

<tasks>

<task type="auto">
  <name>Create Analysis.pike with stateless Analysis class skeleton</name>
  <files>pike-scripts/LSP.pmod/Analysis.pike</files>
  <action>
    Create pike-scripts/LSP.pmod/Analysis.pike with:
    - File header comment following Intelligence.pike pattern
    - Stateless Analysis class with no-op create() method
    - Design notes from CONTEXT.md (stateless, LSP infrastructure usage)
    - Module documentation comment

    Follow Intelligence.pike structure exactly:
    ```pike
    //! Analysis.pike - Stateless analysis class for Pike LSP
    //!
    //! Design per CONTEXT.md:
    //! - Analysis is stateless: all handlers are pure functions
    //! - Analysis uses LSP.Compat.trim_whites() for string operations
    //! - Analysis uses Parser.Pike for tokenization
    //! - Handlers wrap errors in LSP.LSPError responses

    class Analysis {
        //! Create a new Analysis instance
        void create() {
            // No state to initialize (stateless pattern)
        }
    }
    ```
  </action>
  <verify>pike -e "program A = master()->resolv(\"LSP.Analysis\")->Analysis; object a = A();"</verify>
  <done>Analysis class compiles and instantiates without errors</done>
</task>

<task type="auto">
  <name>Add handle_find_occurrences method to Analysis.pike</name>
  <files>pike-scripts/LSP.pmod/Analysis.pike</files>
  <action>
    Add handle_find_occurrences method to Analysis class by extracting from analyzer.pike lines 1233-1300.

    Key implementation details:
    1. Extract params->code (empty string default)
    2. Define keywords multiset inline (all Pike keywords from analyzer.pike)
    3. Wrap tokenization in catch block
    4. Call Parser.Pike.split() then Parser.Pike.tokenize()
    5. Iterate tokens, filter identifiers (start with letter/underscore)
    6. Exclude keywords using has_value()
    7. Build occurrences array with text, line, character
    8. Return LSP.LSPError response on catch

    IMPORTANT MIGRATION from analyzer.pike:
    - Replace String.trim_whites() calls with LSP.Compat.trim_whites()
    - Use LSP.LSPError(-32000, msg)->to_response() for error responses
    - Keep get_char_position as protected helper method in same class

    The keywords multiset should be:
    ```pike
    array(string) keywords = ({
        "if","else","elif","for","while","do","switch","case","break",
        "continue","return","goto","catch","inherit","import",
        "typeof","sscanf","gauge","spawn","foreach","lambda",
        "class","enum","typedef","constant","final","inline",
        "local","extern","static","nomask","private","protected",
        "public","variant","optional","void","zero","mixed",
        "int","float","string","array","mapping","multiset",
        "object","function","program"
    });
    ```

    Response structure (must match existing):
    ```pike
    return ([
        "result": ([
            "occurrences": occurrences
        ])
    ]);
    ```
  </action>
  <verify>pike -e "import LSP.Analysis; Analysis a = Analysis(); mapping r = a->handle_find_occurrences(([\"code\": \"int x; string y;\"])); write(\"%O\n", r);"</verify>
  <done>handle_find_occurrences returns result with occurrences array containing text, line, character for each identifier</done>
</task>

<task type="auto">
  <name>Add get_char_position protected helper to Analysis.pike</name>
  <files>pike-scripts/LSP.pmod/Analysis.pike</files>
  <action>
    Add get_char_position() protected helper method (extracted from analyzer.pike lines 1303-1311).

    This helper converts token line number to character position by finding the token text within the source line.

    Implementation:
    ```pike
    protected int get_char_position(string code, int line_no, string token_text) {
        array lines = code / "\n";
        if (line_no > 0 && line_no <= sizeof(lines)) {
            string line = lines[line_no - 1];
            int pos = search(line, token_text);
            if (pos >= 0) return pos;
        }
        return 0;
    }
    ```

    Mark as protected (not public) - this is Analysis-internal helper for position calculation.
  </action>
  <verify>grep -n "protected int get_char_position" pike-scripts/LSP.pmod/Analysis.pike</verify>
  <done>get_char_position method exists as protected helper</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. Load Analysis.pike in Pike REPL and instantiate Analysis class
2. Call handle_find_occurrences with sample Pike code
3. Verify response structure matches existing analyzer.pike behavior
4. Confirm tokenization errors return proper JSON-RPC error responses
</verification>

<success_criteria>
1. Analysis.pike exists in pike-scripts/LSP.pmod/
2. Analysis class is stateless (no instance variables)
3. handle_find_occurrences returns occurrences array with text, line, character for each identifier
4. Pike keywords are filtered out (no "if", "for", "int" etc. in results)
5. Tokenization errors return LSP.LSPError responses with code -32000
6. All String.trim_whites() replaced with LSP.Compat.trim_whites()
</success_criteria>

<output>
After completion, create `.planning/phases/04-analysis-and-entry-point/04-01-SUMMARY.md`
</output>
