---
phase: 11-startup-optimization
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pike-scripts/analyzer.pike
  - packages/pike-bridge/src/bridge.ts
  - packages/pike-lsp-server/src/services/bridge-manager.ts
autonomous: true
must_haves:
  truths:
    - "Startup phases are timed and emitted in _perf metadata"
    - "Pike subprocess startup time is measured from spawn to ready"
    - "TypeScript bridge startup time is measured from start() to ready"
    - "Timing data is available for before/after comparison"
  artifacts:
    - path: "pike-scripts/analyzer.pike"
      provides: "Pike-side startup timing instrumentation"
      contains: "System.Timer() for startup phases"
    - path: "packages/pike-lsp-server/src/services/bridge-manager.ts"
      provides: "TypeScript-side startup timing"
      contains: "startup timing tracking"
  key_links:
    - from: "pike-scripts/analyzer.pike"
      to: "JSON-RPC responses"
      via: "_perf metadata emission"
      pattern: "_perf.*startup"
    - from: "bridge-manager.ts"
      to: "health status"
      via: "startup timing in health object"
      pattern: "startup.*ms"
---

<objective>
Add startup performance timing instrumentation to measure and track the time spent in each phase of the LSP server initialization.

Purpose: Establish a baseline for startup time to measure the impact of subsequent optimizations. Without timing data, we cannot verify that changes actually improve startup performance.

Output: Instrumented code that emits timing data via _perf metadata and health status, enabling before/after comparison.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-benchmarking-infrastructure/10-03-SUMMARY.md

# Phase 11 Context
@.planning/phases/11-startup-optimization/11-CONTEXT.md

# Current code
@pike-scripts/analyzer.pike
@packages/pike-lsp-server/src/services/bridge-manager.ts
@packages/pike-bridge/src/bridge.ts
@packages/pike-lsp-server/benchmarks/runner.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Pike-side startup timing instrumentation</name>
  <files>pike-scripts/analyzer.pike</files>
  <action>
In analyzer.pike, add startup phase timing instrumentation:

1. At the beginning of main(), create a startup timer: `object startup_timer = System.Timer();`

2. After module path setup (line 133), record path_setup phase time:
   - Create a mapping `mapping startup_phases = ([]);`
   - Store `startup_phases->path_setup = startup_timer->peek() * 1000.0;`

3. Before the JSON-RPC loop begins, record the remaining phases:
   - After version logging (line 138), store `startup_phases->version = startup_timer->peek() * 1000.0;`
   - After HANDLERS initialization (line 197), store `startup_phases->handlers = startup_timer->peek() * 1000.0;`
   - After Context creation (line 200), store `startup_phases->context = startup_timer->peek() * 1000.0;`
   - Store `startup_phases->total = startup_timer->peek() * 1000.0;`

3. Add a new handler "get_startup_metrics" that returns the startup phases:
   ```pike
   "get_startup_metrics": lambda(mapping params, object ctx) {
       return ([
           "result": ([
               "startup": startup_phases
           ])
       ]);
   },
   ```

4. Import System module at top: Add `#pike __REAL_VERSION__` already exists, System.Timer is available.

DO NOT change the startup order or defer anything yet - this is instrumentation-only.
  </action>
  <verify>
1. Check pike-scripts/analyzer.pike compiles: `pike -e 'compile_file("pike-scripts/analyzer.pike");'`
2. Test get_startup_metrics handler:
   ```bash
   echo '{"jsonrpc":"2.0","id":1,"method":"get_startup_metrics","params":{}}' | pike pike-scripts/analyzer.pike
   ```
   Should return startup timing data.
  </verify>
  <done>Startup timing phases are recorded in Pike and accessible via get_startup_metrics RPC call</done>
</task>

<task type="auto">
  <name>Task 2: Add TypeScript-side startup timing in BridgeManager</name>
  <files>packages/pike-lsp-server/src/services/bridge-manager.ts</files>
  <action>
In bridge-manager.ts, track TypeScript-side startup timing:

1. Add private field to track startup start time:
   ```typescript
   private bridgeStartTime: number | null = null;
   ```

2. In start() method, record start time before bridge.start():
   ```typescript
   this.bridgeStartTime = performance.now();
   await this.bridge.start();
   const bridgeReadyTime = performance.now();
   ```

3. After version fetch, calculate and store times:
   ```typescript
   const versionFetchTime = performance.now();
   const startupMetrics = {
       bridgeStart: this.bridgeStartTime,
       bridgeReady: bridgeReadyTime,
       versionFetch: versionFetchTime,
       total: versionFetchTime - this.bridgeStartTime,
   };
   ```

4. Store metrics on the class for health reporting:
   ```typescript
   private startupMetrics: { [key: string]: number } | null = null;
   ```

5. Include startupMetrics in getHealth() return value if available:
   ```typescript
   export interface HealthStatus {
       // ... existing fields
       startupMetrics?: { [key: string]: number } | null;
   }
   ```

DO NOT make version fetch async yet - this is instrumentation-only.
  </action>
  <verify>
1. Build project: `cd packages/pike-lsp-server && pnpm build`
2. Check TypeScript compiles without errors
  </verify>
  <done>TypeScript-side startup timing is tracked and included in health status</done>
</task>

<task type="auto">
  <name>Task 3: Add startup benchmark to runner.ts</name>
  <files>packages/pike-lsp-server/benchmarks/runner.ts</files>
  <action>
In runner.ts, add a dedicated startup benchmark that measures the full cold start:

1. Add a new benchmark case in the "LSP Server Foundations" group:
   ```typescript
   bench('PikeBridge.start() with detailed metrics [Cold Start]', async () => {
       const bridge = new PikeBridge();
       await bridge.start();

       // Fetch startup metrics if available
       try {
           const metrics = await (bridge as any).sendRequest('get_startup_metrics', {});
           // Metrics will be available in _perf or result
       } catch {}

       await bridge.stop();
   });
   ```

2. Track and report startup phases in the Pike metrics section:
   - If startup_phases data is available, report each phase separately
   - Format: "startup.total", "startup.path_setup", "startup.context", etc.

This enables before/after comparison for optimization work.
  </action>
  <verify>
1. Run benchmarks: `cd packages/pike-lsp-server && pnpm bench`
2. Verify startup metrics are printed in the output
  </verify>
  <done>Startup benchmark measures and reports timing for each startup phase</done>
</task>

</tasks>

<verification>
Overall verification:
1. Run `pnpm bench` in packages/pike-lsp-server to verify startup metrics are collected
2. Check that get_startup_metrics returns valid timing data
3. Verify health status includes startup timing information
</verification>

<success_criteria>
1. All startup phases are timed in Pike (path_setup, version, handlers, context, total)
2. TypeScript bridge start time is tracked (bridgeReady, versionFetch, total)
3. get_startup_metrics RPC call returns structured timing data
4. Benchmark suite reports startup phase breakdown
5. Baseline timing is established for before/after comparison
</success_criteria>

<output>
After completion, create `.planning/phases/11-startup-optimization/11-01-SUMMARY.md`
</output>
