---
phase: 11-startup-optimization
plan: 05
type: execute
wave: 3
depends_on: [11-01, 11-02, 11-03, 11-04]
files_modified:
  - packages/pike-lsp-server/benchmarks/runner.ts
  - benchmark-results.json
autonomous: true
must_haves:
  truths:
    - "Startup time is under 500ms (measured by benchmark)"
    - "Before/after comparison shows improvement"
    - "All startup phases are documented with timings"
  artifacts:
    - path: "packages/pike-lsp-server/benchmarks/runner.ts"
      provides: "Startup performance benchmark"
      contains: "startup timing benchmarks"
    - path: "benchmark-results.json"
      provides: "Baseline performance data"
      contains: "startup timing results"
  key_links:
    - from: "runner.ts benchmarks"
      to: "startup metrics"
      via: "benchmark execution"
      pattern: "startup.*bench"
    - from: "benchmark-results.json"
      to: "ROADMAP.md"
      via: "performance tracking"
      pattern: "\"startup\":"
---

<objective>
Run comprehensive benchmarks to verify that startup time is under 500ms and document the improvements from all optimizations.

Purpose: Validate that the startup optimization phase achieved its goal (<500ms startup) and establish a new baseline for future work. This also confirms that all optimizations work together without regressions.

Output: Benchmark results showing startup time under 500ms; before/after comparison; updated baseline in benchmark-results.json.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Phase 11 Context
@.planning/phases/11-startup-optimization/11-CONTEXT.md

# Current code
@packages/pike-lsp-server/benchmarks/runner.ts
@.planning/BENCHMARKS.md

# Prior work
@.planning/phases/11-startup-optimization/11-01-SUMMARY.md
@.planning/phases/11-startup-optimization/11-02-SUMMARY.md
@.planning/phases/11-startup-optimization/11-03-SUMMARY.md
@.planning/phases/11-startup-optimization/11-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run startup benchmarks and collect results</name>
  <files>packages/pike-lsp-server/benchmarks/runner.ts</files>
  <action>
Run the full benchmark suite to measure startup performance:

1. Navigate to benchmark directory:
   ```bash
   cd packages/pike-lsp-server
   ```

2. Run benchmarks with JSON output:
   ```bash
   MITATA_JSON=benchmark-results.json pnpm bench
   ```

3. This will execute all startup benchmarks including:
   - PikeBridge.start() [Cold Start]
   - Cold Start + First Request (getVersionInfo)
   - Cold Start + Introspect
   - Startup phase breakdowns (if added in 11-01)

4. Capture the output and note the key metrics:
   - Cold start time (ms)
   - First request overhead (ms)
   - Individual phase timings (path_setup, version, context, etc.)

5. Run multiple iterations (3-5 runs) to get consistent measurements:
   ```bash
   for i in {1..5}; do
       echo "Run $i:"
       pnpm bench 2>&1 | grep "Cold Start"
   done
   ```

This provides reliable data for performance validation.
  </action>
  <verify>
1. Benchmark suite completes without errors
2. JSON results file is created with timing data
3. All startup phases have measurements
  </verify>
  <done>Benchmark suite executed with JSON results captured</done>
</task>

<task type="auto">
  <name>Task 2: Verify <500ms goal and document results</name>
  <files>benchmark-results.json</files>
  <action>
Analyze benchmark results and verify the <500ms goal:

1. Read benchmark-results.json and extract startup timing:
   - Find "PikeBridge.start() [Cold Start]" result
   - Check if mean time is <500ms

2. If goal achieved:
   - Update benchmark-results.json with new baseline
   - Add "startup_optimization_complete": true flag
   - Document before/after comparison

3. If goal NOT achieved:
   - Identify which phase is still slow
   - Check if individual phases are documented
   - Note potential next steps

4. Create a summary in the results file:
   ```json
   {
       "startup_goal": "<500ms",
       "achieved": true/false,
       "measured": "Xms",
       "optimizations": [
           "Lazy Context creation",
           "Removed LSP.Compat startup load",
           "Async version fetch"
       ]
   }
   ```

5. If goal is achieved, update BENCHMARKS.md with new startup baseline.

This documents the outcome of the optimization phase.
  </action>
  <verify>
1. benchmark-results.json contains startup goal status
2. If achieved, BENCHMARKS.md is updated with new baseline
3. Before/after comparison is documented
  </verify>
  <done>Startup goal status documented; baseline updated if goal achieved</done>
</task>

<task type="auto">
  <name>Task 3: Run E2E verification</name>
  <files>packages/vscode-pike</files>
  <action>
Run full E2E test suite to ensure optimizations didn't break functionality:

1. Run E2E tests:
   ```bash
   cd packages/vscode-pike
   pnpm test:features
   ```

2. Verify all core features work:
   - Document symbols
   - Hover info
   - Go to definition
   - Completion

3. If any test fails:
   - Investigate if related to lazy loading
   - Check if Context is being created properly
   - Verify timing doesn't cause race conditions

4. Run manual smoke test if needed:
   ```bash
   echo '{"jsonrpc":"2.0","id":1,"method":"introspect","params":{"code":"int x;","filename":"test.pike"}}' \
     | pike ../../pike-scripts/analyzer.pike
   ```

This ensures optimizations preserve correctness.
  </action>
  <verify>
1. All E2E tests pass
2. Manual smoke test returns valid results
3. No regressions in LSP functionality
  </verify>
  <done>E2E tests pass; all LSP features work correctly</done>
</task>

</tasks>

<verification>
Overall verification:
1. Benchmark results show startup time under 500ms
2. E2E tests pass completely
3. Before/after comparison demonstrates improvement
4. Baseline is updated for future phases
</verification>

<success_criteria>
1. Pike subprocess cold start is under 500ms
2. E2E tests pass without modification
3. Benchmark results are documented
4. Performance improvement is quantified
5. Ready to proceed to Phase 12 (Request Consolidation)
</success_criteria>

<output>
After completion, create `.planning/phases/11-startup-optimization/11-05-SUMMARY.md`
</output>
